{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77179fd8-ce2d-4f1c-a0b5-d90bce056ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjwhit/rcGAN/fastmri/__init__.py:16: UserWarning: Could not retrieve fastmri version!\n",
      "  warnings.warn(\"Could not retrieve fastmri version!\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jjwhit/rcGAN/')\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from models.lightning.mmGAN import mmGAN\n",
    "from models.archs.mri.generator import UNetModel\n",
    "from models.archs.mri.discriminator import DiscriminatorModel\n",
    "from data.lightning.MassMappingDataModule import MMDataTransform\n",
    "\n",
    "import yaml\n",
    "import json\n",
    "import types\n",
    "import torch\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b50fc372-87b5-435e-ab6b-d69b0cb9125a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'im_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m examples_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/share/gpu0/jjwhit/kappa_cosmos_simulations/cropped_dataset/kappa_val/cropped_sim_08649.npy\u001b[39m\u001b[38;5;124m'\u001b[39m \n\u001b[1;32m      3\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mim_size\u001b[39m\u001b[38;5;124m'\u001b[39m:(\u001b[38;5;241m300\u001b[39m,\u001b[38;5;241m300\u001b[39m)}\n\u001b[0;32m----> 5\u001b[0m transform \u001b[38;5;241m=\u001b[39m \u001b[43mMMDataTransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(examples_path, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mcomplex128)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Tranform data and generate observations\u001b[39;00m\n",
      "File \u001b[0;32m~/rcGAN/data/lightning/MassMappingDataModule.py:19\u001b[0m, in \u001b[0;36mMMDataTransform.__init__\u001b[0;34m(self, args, test, theta, ngal)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest \u001b[38;5;241m=\u001b[39m test\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtheta \u001b[38;5;241m=\u001b[39m theta\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim_size \u001b[38;5;241m=\u001b[39m \u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim_size\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngal \u001b[38;5;241m=\u001b[39m ngal\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'im_size'"
     ]
    }
   ],
   "source": [
    "examples_path = '/share/gpu0/jjwhit/kappa_cosmos_simulations/cropped_dataset/kappa_val/cropped_sim_08649.npy' \n",
    "\n",
    "args = {'im_size':(300,300)}\n",
    "\n",
    "transform = MMDataTransform(args)\n",
    "\n",
    "data = np.load(examples_path, allow_pickle=True).astype(np.complex128)\n",
    "# Tranform data and generate observations\n",
    "data_transformed = transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43413491-565c-4963-9e1a-aa7ec852f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x, mean, std = data_transformed\n",
    "\n",
    "y = y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32ed5d1f-a6d5-4f25-8d10-ce9026db87de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1024, 1024])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "503c7313-1988-465f-8bf5-8412aa8d8d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 1024, 1024])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y[None,:,:,:]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9e3026b-4499-4dc0-aa99-371682e7303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise(num_vectors):\n",
    "    z = torch.randn(num_vectors, 2, 1024, 1024, device=device)\n",
    "    return z\n",
    "\n",
    "num_vectors = y.size(0)\n",
    "\n",
    "noise = get_noise(num_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae5c510d-d0fb-45f5-beaf-bce09bc190be",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_input = torch.cat([y, noise], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "928bef9f-ff0f-4ce6-8374-7687c2d5bc61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_input.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da2f24f7-3afe-4313-bd7d-c9dc4475e652",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_input = gen_input.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "517c93c7-0acb-4a60-b33d-d4ab4b2ca8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.archs.mri.generator import UNetModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b96a70b-50d4-4d9d-8f9c-4bcf0ad4b70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_chans = 2 + 2\n",
    "out_chans = 2\n",
    "\n",
    "generator = UNetModel(\n",
    "    in_chans=in_chans,\n",
    "    out_chans=out_chans,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b26874dc-a7ab-49f1-9ab0-a18bc95ccdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "samples = generator(gen_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a7d3dca-5db0-44b3-8602-06c40252ce67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 1024, 1024])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc19363-fe1d-4686-a798-fc170c70f355",
   "metadata": {},
   "outputs": [],
   "source": [
    "reformatted_tensor = reformat(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730e2c23-d5d5-4cbc-8228-4189521d8a45",
   "metadata": {},
   "source": [
    "## Readd_measures Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d4d2b4-3f7f-48e2-a560-b98da6c917c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat(self, samples):\n",
    "    reformatted_tensor = torch.zeros(size=(samples.size(0), 1, self.resolution, self.resolution, 2),\n",
    "                                     device=self.device)\n",
    "    #Takes values from samples and assigns to reformatted tensor\n",
    "    #assumption: 0:8 for real, 8:16 for complex, multiple elements bc multiple MRI slices?\n",
    "    reformatted_tensor[:, :, :, :, 0] = samples[:, 0, :, :]\n",
    "    reformatted_tensor[:, :, :, :, 1] = samples[:, 1, :, :]\n",
    "\n",
    "    return reformatted_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d1d0fe-9f93-44f0-aa50-1a1d15ab872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readd_measures(self, samples, measures):\n",
    "    reformatted_tensor = self.reformat(samples)\n",
    "    measures = fft2c_new(self.reformat(measures))\n",
    "    reconstructed_kspace = fft2c_new(reformatted_tensor)\n",
    "\n",
    "    # reconstructed_kspace = mask * measures + (1 - mask) * reconstructed_kspace\n",
    "\n",
    "    image = ifft2c_new(reconstructed_kspace)\n",
    "\n",
    "    output_im = torch.zeros(size=samples.shape, device=self.device)\n",
    "    output_im[:, 0, :, :] = image[:, :, :, :, 0]\n",
    "    output_im[:, 1, :, :] = image[:, :, :, :, 1]\n",
    "\n",
    "    return output_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ffc67320-1d3c-4985-9759-579b3f9b81fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "reformatted_tensor = torch.zeros(size=(5, 1024, 1024, 2), device=device)\n",
    "\n",
    "ex_samples = torch.zeros(size=(5, 2, 1024, 1024), device=device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fe15cb98-9f7d-4895-a46b-6034afd7ed49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1024, 1024])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ex_samples[:, 0, :, :].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fbb7d6c4-ce17-49ad-a5d8-645f3b55530e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1024, 1024])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reformatted_tensor[:, :, :, 0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3072a872-bcfd-4c1a-91cd-9a08e15eec39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 1024, 1024])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7c614c0d-a200-4483-802f-d95fea1c81a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1024, 1024])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(ex_samples, dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c800f58-f6c4-443a-a984-e102fc68f213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa4ca64-5204-4241-95a2-b9da49a31976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f326aae0-9964-4f12-8a74-b970e2b8aa31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a1c933-2423-46ab-a6ee-b3273cf12484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f4585d-a735-44b5-ac81-f4968763e977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4611a66e-9666-4b3e-be55-c01efd8ad196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import torch.autograd as autograd\n",
    "from matplotlib import cm\n",
    "from PIL import Image\n",
    "from torch.nn import functional as F\n",
    "from models.archs.mass_map.generator import UNetModel\n",
    "from models.archs.mass_map.discriminator import DiscriminatorModel\n",
    "from evaluation_scripts.metrics import psnr\n",
    "from torchmetrics.functional import peak_signal_noise_ratio\n",
    "\n",
    "class mmGAN(pl.LightningModule):\n",
    "    def __init__(self, args, exp_name, num_gpus):\n",
    "        super().__init__()\n",
    "        self.args = args # This is the cfg object \n",
    "        self.exp_name = exp_name\n",
    "        self.num_gpus = num_gpus\n",
    "\n",
    "        self.in_chans = args.in_chans + 2  # Two extra dimensions of the added noise \n",
    "        self.out_chans = args.out_chans\n",
    "\n",
    "        self.generator = UNetModel(\n",
    "            in_chans=self.in_chans,\n",
    "            out_chans=self.out_chans,\n",
    "        )\n",
    "\n",
    "        self.discriminator = DiscriminatorModel(\n",
    "            in_chans=self.args.in_chans + self.args.out_chans, # Number of channels from x and y\n",
    "            out_chans=self.out_chans,\n",
    "            input_im_size=self.args.im_size\n",
    "        )\n",
    "\n",
    "        self.std_mult = 1\n",
    "        self.is_good_model = 0\n",
    "        self.resolution = self.args.im_size\n",
    "\n",
    "        self.save_hyperparameters()  # Save passed values\n",
    "\n",
    "    def get_noise(self, num_vectors):\n",
    "        z = torch.randn(num_vectors, 2, self.resolution, self.resolution, device=self.device)\n",
    "        return z\n",
    "\n",
    "    def reformat(self, samples):\n",
    "        reformatted_tensor = torch.swapaxes(torch.clone(samples), 3, 1)\n",
    "        return reformatted_tensor\n",
    "\n",
    "    def readd_measures(self, samples, measures):\n",
    "        return torch.clone(samples)\n",
    "\n",
    "    def compute_gradient_penalty(self, real_samples, fake_samples, y):\n",
    "        \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "        Tensor = torch.FloatTensor\n",
    "        # Random weight term for interpolation between real and fake samples\n",
    "        alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1))).to(self.device)\n",
    "        # Get random interpolation between real and fake samples\n",
    "        interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "        d_interpolates = self.discriminator(input=interpolates, y=y)\n",
    "        # fake = Tensor(real_samples.shape[0], 1, d_interpolates.shape[-1], d_interpolates.shape[-1]).fill_(1.0).to(\n",
    "        #     self.device)\n",
    "        fake = Tensor(real_samples.shape[0], 1).fill_(1.0).to(\n",
    "            self.device)\n",
    "\n",
    "        # Get gradient w.r.t. interpolates\n",
    "        gradients = autograd.grad(\n",
    "            outputs=d_interpolates,\n",
    "            inputs=interpolates,\n",
    "            grad_outputs=fake,\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            only_inputs=True,\n",
    "        )[0]\n",
    "        gradients = gradients.view(gradients.size(0), -1)\n",
    "        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "        return gradient_penalty\n",
    "\n",
    "    def forward(self, y):\n",
    "        num_vectors = y.size(0)\n",
    "        noise = self.get_noise(num_vectors)\n",
    "        samples = self.generator(torch.cat([y, noise], dim=1))\n",
    "        samples = self.readd_measures(samples, y)     \n",
    "        return samples\n",
    "\n",
    "    def adversarial_loss_discriminator(self, fake_pred, real_pred):\n",
    "        return fake_pred.mean() - real_pred.mean()\n",
    "\n",
    "    def adversarial_loss_generator(self, y, gens):\n",
    "        fake_pred = torch.zeros(size=(y.shape[0], self.args.num_z_train), device=self.device)\n",
    "        for k in range(y.shape[0]):\n",
    "            cond = torch.zeros(\n",
    "                1,\n",
    "                self.args.in_chans,\n",
    "                self.args.im_size,\n",
    "                self.args.im_size,\n",
    "                device=self.device\n",
    "            )\n",
    "            cond[0, :, :, :] = y[k, :, :, :]\n",
    "            cond = cond.repeat(self.args.num_z_train, 1, 1, 1)\n",
    "            temp = self.discriminator(input=gens[k], y=cond)\n",
    "            fake_pred[k] = temp[:, 0]\n",
    "\n",
    "        gen_pred_loss = torch.mean(fake_pred[0])\n",
    "        for k in range(y.shape[0] - 1):\n",
    "            gen_pred_loss += torch.mean(fake_pred[k + 1])\n",
    "\n",
    "        adv_weight = 1e-5\n",
    "        if self.current_epoch <= 4:\n",
    "            adv_weight = 1e-2\n",
    "        elif self.current_epoch <= 22:\n",
    "            adv_weight = 1e-4\n",
    "\n",
    "        return - adv_weight * gen_pred_loss.mean()\n",
    "\n",
    "    def l1_std_p(self, avg_recon, gens, x):\n",
    "        return F.l1_loss(avg_recon, x) - self.std_mult * np.sqrt(\n",
    "            2 / (np.pi * self.args.num_z_train * (self.args.num_z_train+ 1))\n",
    "            ) * torch.std(gens, dim=1).mean()\n",
    "\n",
    "    def gradient_penalty(self, x_hat, x, y):\n",
    "        gradient_penalty = self.compute_gradient_penalty(x.data, x_hat.data, y.data)\n",
    "\n",
    "        return self.args.gp_weight * gradient_penalty\n",
    "\n",
    "    def drift_penalty(self, real_pred):\n",
    "        return 0.001 * torch.mean(real_pred ** 2)\n",
    "\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        y, x, mean, std = batch\n",
    "\n",
    "        # train generator\n",
    "        if optimizer_idx == 1:\n",
    "            gens = torch.zeros(\n",
    "                size=(\n",
    "                    y.size(0),\n",
    "                    self.args.num_z_train,\n",
    "                    self.args.out_chans,\n",
    "                    self.args.im_size, \n",
    "                    self.args.im_size\n",
    "                ),\n",
    "                device=self.device)\n",
    "            for z in range(self.args.num_z_train):\n",
    "                gens[:, z, :, :, :] = self.forward(y)\n",
    "\n",
    "            avg_recon = torch.mean(gens, dim=1)\n",
    "\n",
    "            # adversarial loss is binary cross-entropy\n",
    "            g_loss = self.adversarial_loss_generator(y, gens)\n",
    "            g_loss += self.l1_std_p(avg_recon, gens, x)\n",
    "\n",
    "            self.log('g_loss', g_loss, prog_bar=True)\n",
    "\n",
    "            return g_loss\n",
    "\n",
    "        # train discriminator\n",
    "        if optimizer_idx == 0:\n",
    "            x_hat = self.forward(y)\n",
    "\n",
    "            real_pred = self.discriminator(input=x, y=y)\n",
    "            fake_pred = self.discriminator(input=x_hat, y=y)\n",
    "\n",
    "            d_loss = self.adversarial_loss_discriminator(fake_pred, real_pred)\n",
    "            d_loss += self.gradient_penalty(x_hat, x, y)\n",
    "            d_loss += self.drift_penalty(real_pred)\n",
    "\n",
    "            self.log('d_loss', d_loss, prog_bar=True)\n",
    "\n",
    "            return d_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx, external_test=False):\n",
    "        y, x, mean, std= batch\n",
    "\n",
    "        fig_count = 0\n",
    "\n",
    "        if external_test:\n",
    "            num_code = self.args.num_z_test\n",
    "        else:\n",
    "            num_code = self.args.num_z_valid\n",
    "        \n",
    "        kappa_mean = torch.tensor([self.args.kappa_mean], device=self.device)\n",
    "        kappa_std = torch.tensor([self.args.kappa_std], device=self.device)\n",
    "\n",
    "        gens = torch.zeros(size=(y.size(0), num_code, self.args.out_chans, self.args.im_size, self.args.im_size),\n",
    "                           device=self.device)\n",
    "        for z in range(num_code):\n",
    "            # gens[:, z, :, :, :] = self.forward(y) * std[:, None, None, None] + mean[:, None, None, None] \n",
    "            gens[:, z, :, :, :] = self.forward(y) * kappa_std[:, None, None, None] + kappa_mean[:, None, None, None] #TODO: All good here?\n",
    "\n",
    "        avg = torch.mean(gens, dim=1)\n",
    "        avg_gen = self.reformat(avg)\n",
    "        # gt = self.reformat(x * std[:, None, None, None] + mean[:, None, None, None])\n",
    "        gt = self.reformat(x * kappa_std[:, None, None, None] + kappa_mean[:, None, None, None])\n",
    "\n",
    "        mag_avg_list = []\n",
    "        mag_single_list = []\n",
    "        mag_gt_list = []\n",
    "        psnr_8s = []\n",
    "        psnr_1s = []\n",
    "\n",
    "        for j in range(y.size(0)):\n",
    "            psnr_8s.append(peak_signal_noise_ratio(avg_gen[j], gt[j]))\n",
    "            psnr_1s.append(peak_signal_noise_ratio(self.reformat(gens[:, 0])[j], gt[j]))\n",
    "\n",
    "            mag_avg_list.append(avg_gen[None, j, :, :, :])\n",
    "            mag_single_list.append(self.reformat(gens[:, 0])[j])\n",
    "            mag_gt_list.append(gt[None, j, :, :, :])\n",
    "\n",
    "        psnr_8s = torch.stack(psnr_8s)\n",
    "        psnr_1s = torch.stack(psnr_1s)\n",
    "        mag_avg_gen = torch.cat(mag_avg_list, dim=0)\n",
    "        mag_gt = torch.cat(mag_gt_list, dim=0)\n",
    "\n",
    "        self.log('psnr_8_step', psnr_8s.mean(), on_step=True, on_epoch=False, prog_bar=True)\n",
    "        self.log('psnr_1_step', psnr_1s.mean(), on_step=True, on_epoch=False, prog_bar=True)\n",
    "\n",
    "        if batch_idx == 0:\n",
    "            if self.global_rank == 0 and self.current_epoch % 1 == 0 and fig_count == 0:\n",
    "                fig_count += 1\n",
    "                # Using single generation instead of avg generator (mag_avg_gen)\n",
    "                avg_gen_np = mag_avg_gen[0, :, :, 0].cpu().numpy()\n",
    "                gt_np = mag_gt[0, :, :, 0].cpu().numpy()\n",
    "\n",
    "                plot_avg_np = (avg_gen_np - np.min(avg_gen_np)) / (np.max(avg_gen_np) - np.min(avg_gen_np))\n",
    "                plot_gt_np = (gt_np - np.min(gt_np)) / (np.max(gt_np) - np.min(gt_np))\n",
    "\n",
    "                np_psnr = psnr(gt_np, avg_gen_np)\n",
    "\n",
    "                self.logger.log_image(\n",
    "                    key=f\"epoch_{self.current_epoch}_img\",\n",
    "                    images=[\n",
    "                        Image.fromarray(np.uint8(plot_gt_np*255), 'L'),\n",
    "                        Image.fromarray(np.uint8(plot_avg_np*255), 'L'),\n",
    "                        Image.fromarray(np.uint8(cm.jet(5*np.abs(plot_gt_np - plot_avg_np))*255))\n",
    "                    ],\n",
    "                    caption=[\"GT\", f\"Recon: PSNR (NP): {np_psnr:.2f}\", \"Error\"]\n",
    "                )\n",
    "\n",
    "            self.trainer.strategy.barrier()\n",
    "\n",
    "        return {'psnr_8': psnr_8s.mean(), 'psnr_1': psnr_1s.mean()}\n",
    "\n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "        avg_psnr = self.all_gather(torch.stack([x['psnr_8'] for x in validation_step_outputs]).mean()).mean()\n",
    "        avg_single_psnr = self.all_gather(torch.stack([x['psnr_1'] for x in validation_step_outputs]).mean()).mean()\n",
    "\n",
    "        avg_psnr = avg_psnr.cpu().numpy()\n",
    "        avg_single_psnr = avg_single_psnr.cpu().numpy()\n",
    "\n",
    "        psnr_diff = (avg_single_psnr + 2.5) - avg_psnr\n",
    "\n",
    "        mu_0 = 2e-2\n",
    "        self.std_mult += mu_0 * psnr_diff\n",
    "\n",
    "        if np.abs(psnr_diff) <= self.args.psnr_gain_tol:\n",
    "            self.is_good_model = 1\n",
    "        else:\n",
    "            self.is_good_model = 0\n",
    "\n",
    "        self.trainer.strategy.barrier()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt_g = torch.optim.Adam(\n",
    "            self.generator.parameters(),\n",
    "            lr=self.args.lr,\n",
    "            betas=(self.args.beta_1, self.args.beta_2)\n",
    "        )\n",
    "        opt_d = torch.optim.Adam(\n",
    "            self.discriminator.parameters(),\n",
    "            lr=self.args.lr,\n",
    "            betas=(self.args.beta_1, self.args.beta_2)\n",
    "        )\n",
    "        return [opt_d, opt_g], []\n",
    "\n",
    "    def on_save_checkpoint(self, checkpoint):\n",
    "        checkpoint[\"beta_std\"] = self.std_mult\n",
    "        checkpoint[\"is_valid\"] = self.is_good_model\n",
    "\n",
    "    def on_load_checkpoint(self, checkpoint):\n",
    "        self.std_mult = checkpoint[\"beta_std\"]\n",
    "        self.is_good_model = checkpoint[\"is_valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb48e93-ee14-4c44-a377-aae04e0e1e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faedbd9-8983-4898-a9e3-ae5e602c6c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131399db-b950-4a84-9d4f-e25819b1f02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjwhit/rcGAN/fastmri/__init__.py:16: UserWarning: Could not retrieve fastmri version!\n",
      "  warnings.warn(\"Could not retrieve fastmri version!\")\n",
      "[rank: 0] Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Name: mmgan_debug\n",
      "Number of GPUs: 1\n",
      "Device count:  1\n",
      "Config file path: /home/jjwhit/rcGAN/configs/mass_map_test.yml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjess-j-whitney\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/share/gpu0/jjwhit/mass_map/mm_models/wandb/wandb/run-20240819_165937-frdoici1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jess-j-whitney/mass_mapping/runs/frdoici1' target=\"_blank\">mmgan_debug</a></strong> to <a href='https://wandb.ai/jess-j-whitney/mass_mapping' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jess-j-whitney/mass_mapping' target=\"_blank\">https://wandb.ai/jess-j-whitney/mass_mapping</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jess-j-whitney/mass_mapping/runs/frdoici1' target=\"_blank\">https://wandb.ai/jess-j-whitney/mass_mapping/runs/frdoici1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[rank: 0] Global seed set to 0\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "[W socket.cpp:426] [c10d] The server socket cannot be initialized on [::]:24411 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [compute-gpu-0-3.local]:24411 (errno: 97 - Address family not supported by protocol).\n",
      "[W socket.cpp:601] [c10d] The client socket cannot be initialized to connect to [compute-gpu-0-3.local]:24411 (errno: 97 - Address family not supported by protocol).\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | generator     | UNetModel          | 195 M \n",
      "1 | discriminator | DiscriminatorModel | 6.3 M \n",
      "-----------------------------------------------------\n",
      "202 M     Trainable params\n",
      "0         Non-trainable params\n",
      "202 M     Total params\n",
      "808.525   Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/jjwhit/rcGAN/data/lightning/MassMappingDataModule.py:96: RuntimeWarning: divide by zero encountered in divide\n",
      "  F_kappa = F_gamma / D\n",
      "/home/jjwhit/.conda/envs/cGAN/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b2d8cfa59d4d439b6d943dd0c723f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjwhit/rcGAN/data/lightning/MassMappingDataModule.py:96: RuntimeWarning: divide by zero encountered in divide\n",
      "  F_kappa = F_gamma / D\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjwhit/rcGAN/data/lightning/MassMappingDataModule.py:96: RuntimeWarning: divide by zero encountered in divide\n",
      "  F_kappa = F_gamma / D\n",
      "/home/jjwhit/rcGAN/data/lightning/MassMappingDataModule.py:96: RuntimeWarning: divide by zero encountered in divide\n",
      "  F_kappa = F_gamma / D\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjwhit/rcGAN/data/lightning/MassMappingDataModule.py:96: RuntimeWarning: divide by zero encountered in divide\n",
      "  F_kappa = F_gamma / D\n",
      "/home/jjwhit/rcGAN/data/lightning/MassMappingDataModule.py:96: RuntimeWarning: divide by zero encountered in divide\n",
      "  F_kappa = F_gamma / D\n"
     ]
    }
   ],
   "source": [
    "%run /home/jjwhit/rcGAN/train.py --config /home/jjwhit/rcGAN/configs/mass_map_test.yml --exp-name mmgan_debug --num-gpus 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c497c16b-f5bb-4ce3-ae36-7f012437168f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cGAN",
   "language": "python",
   "name": "cgan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
